{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3570,"status":"ok","timestamp":1711723630208,"user":{"displayName":"Gia Huy Tong","userId":"14695060995051312742"},"user_tz":-420},"id":"6CUkgLyh_CEH","outputId":"e180a653-ece2-4c6c-ac8c-902ee3b468e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","\n"]}],"source":["import torch\n","\n","\n","# print(torch.cuda.current_device())\n","# print(torch.cuda.device(0))\n","# print(torch.cuda.device_count())\n","# print(torch.cuda.get_device_name(0))\n","# print(torch.cuda.is_available())\n","\n","# setting device on GPU if available, else CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","# additional info when using cuda\n","if device.type == 'cuda':\n","  print(torch.cuda.get_device_name(0))\n","  print('Memory Usage:')\n","  print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","  print('Cached: ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7212,"status":"ok","timestamp":1711723685365,"user":{"displayName":"Gia Huy Tong","userId":"14695060995051312742"},"user_tz":-420},"id":"y7rD_M2pKx-N","outputId":"8a5e328d-5f17-4836-fc5b-addbfc797e25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorboardX in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboardX) (1.26.4)\n","Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboardX) (4.25.4)\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["log file path:log/log_2024-08-25_09-37-44.txt\n","2024-08-25 09:37:44,620 train.py[line:614] INFO: Using device cpu\n","/Users/anphong/Documents/School/ML/pytorch-YOLOv4/models.py:426: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  pretrained_dict = torch.load(yolov4conv137weight)\n","2024-08-25 09:37:44,876 train.py[line:313] INFO: Starting training:\n","        Epochs:          100\n","        Batch size:      4\n","        Subdivisions:    1\n","        Learning rate:   0.001\n","        Training size:   202\n","        Validation size: 58\n","        Checkpoints:     True\n","        Device:          cpu\n","        Images size:     416\n","        Optimizer:       adam\n","        Dataset classes: 9\n","        Train label path:train.txt\n","        Pretrained:\n","    \n","Epoch 1/100:   0%|       | 0/202 [00:00<?, ?img/s][ WARN:0@1.770] global loadsave.cpp:241 findDecoder imread_('train/dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.065f8833508d101a1f1449e8fbabc314.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.778] global loadsave.cpp:241 findDecoder imread_('train/6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.e6bfa3034bc8005aaadf8ba1aca18e61.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.467] global loadsave.cpp:241 findDecoder imread_('train/9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.3903667901a40aedda2c42c43502d96b.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.554] global loadsave.cpp:241 findDecoder imread_('train/8967433350d3b3043902603430fccaab_jpg.rf.b3b6e9ca2da2674266a7d44c368a3953.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.468] global loadsave.cpp:241 findDecoder imread_('train/bc5decab88861286dcf78a367b4377cb_jpg.rf.99264d2583f17e6ba8a7b2e15c54271a.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.555] global loadsave.cpp:241 findDecoder imread_('train/8bb72e70f0560095885586deba37a524_jpg.rf.addedc80f989194e077b8c53871457b8.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.498] global loadsave.cpp:241 findDecoder imread_('train/0f4512d71c096f2699d705792e88fc58_jpg.rf.0971fe35ffe3ebbcc3e2a709de978aec.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.499] global loadsave.cpp:241 findDecoder imread_('train/80c787b97ed3e2b4befd6b11aa2fba37_jpg.rf.b7e9d028eb34400c5d239b57639e086e.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.546] global loadsave.cpp:241 findDecoder imread_('train/f1ea0167087976926d4fe0aa36b961ce_jpg.rf.ab4d245320384c2d04ba6e9ba6a652ec.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.547] global loadsave.cpp:241 findDecoder imread_('train/3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.d5f14cd80477f444b7ed601f609c67dd.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.574] global loadsave.cpp:241 findDecoder imread_('train/97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.5997f0ef95b45103711d4fdc239c2691.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.630] global loadsave.cpp:241 findDecoder imread_('train/2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.c546a535eb5f3a68ed59a794c1faeb2a.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.631] global loadsave.cpp:241 findDecoder imread_('train/3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.d17abcc1ddc47bcc382536d9669e3fd5.jpg'): can't open/read file: check file path/integrity\n","[ WARN:0@1.575] global loadsave.cpp:241 findDecoder imread_('train/9e943906fba1ec89edfacb2dd7976504_jpg.rf.9702132e48df03814384024ca7313212.jpg'): can't open/read file: check file path/integrity\n","Epoch 1/100:   0%|       | 0/202 [00:02<?, ?img/s]\n","[ WARN:0@1.631] global loadsave.cpp:241 findDecoder imread_('train/beb11566e59775b61f0ca369952067cc_jpg.rf.f2f174dcc0acd5991b822c5ca1a6735a.jpg'): can't open/read file: check file path/integrity\n","Traceback (most recent call last):\n","  File \"/Users/anphong/Documents/School/ML/pytorch-YOLOv4/train.py\", line 626, in <module>\n","    train(model=model,\n","  File \"/Users/anphong/Documents/School/ML/pytorch-YOLOv4/train.py\", line 370, in train\n","    for i, batch in enumerate(train_loader):\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n","    data = self._next_data()\n","           ^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1344, in _next_data\n","    return self._process_data(data)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1370, in _process_data\n","    data.reraise()\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py\", line 706, in reraise\n","    raise exception\n","cv2.error: Caught error in DataLoader worker process 0.\n","Original Traceback (most recent call last):\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n","    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","            ~~~~~~~~~~~~^^^^^\n","  File \"/Users/anphong/Documents/School/ML/pytorch-YOLOv4/dataset.py\", line 297, in __getitem__\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","cv2.error: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","\n","\n","Exception ignored in atexit callback: <function _exit_function at 0x133bfaa20>\n","Traceback (most recent call last):\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/util.py\", line 360, in _exit_function\n","    p.join()\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 149, in join\n","    res = self._popen.wait(timeout)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n","    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n","    pid, sts = os.waitpid(self.pid, flag)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 67, in handler\n","    _error_if_any_worker_fails()\n","RuntimeError: DataLoader worker (pid 4545) is killed by signal: Terminated: 15. \n"]}],"source":["!python3 train.py -l 0.001 -g 0 -pretrained ./yolov4.conv.137.pth -classes 9 -dir train"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274011,"status":"ok","timestamp":1711723965282,"user":{"displayName":"Gia Huy Tong","userId":"14695060995051312742"},"user_tz":-420},"id":"8SZsXdQiKt2o","outputId":"b963e429-bab3-4681-ddfc-2551ec949e88"},"outputs":[{"name":"stdout","output_type":"stream","text":["log file path:log/log_2024-03-29_14-48-21.txt\n","2024-03-29 14:48:21,058 train.py[line:614] INFO: Using device cuda\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","2024-03-29 14:48:32,051 train.py[line:313] INFO: Starting training:\n","        Epochs:          6\n","        Batch size:      4\n","        Subdivisions:    1\n","        Learning rate:   0.001\n","        Training size:   202\n","        Validation size: 58\n","        Checkpoints:     True\n","        Device:          cuda\n","        Images size:     416\n","        Optimizer:       adam\n","        Dataset classes: 12\n","        Train label path:train.txt\n","        Pretrained:\n","    \n","Epoch 1/6:  38%|▍| 76/202 [00:15<00:12,  9.81img/s/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:271: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","Epoch 1/6:  99%|▉| 200/202 [00:28<00:00, 11.20img/in function convert_to_coco_api...\n","creating index...\n","index created!\n","Epoch 1/6:  99%|▉| 200/202 [00:40<00:00, 11.20img/Accumulating evaluation results...\n","DONE (t=0.42s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.225\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.118\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.141\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.299\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","2024-03-29 14:49:22,002 train.py[line:446] INFO: Created checkpoint directory\n","2024-03-29 14:49:22,862 train.py[line:454] INFO: Checkpoint 1 saved !\n","Epoch 1/6:  99%|▉| 200/202 [00:50<00:00,  3.94img/\n","Epoch 2/6:  99%|▉| 200/202 [00:26<00:00,  9.82img/in function convert_to_coco_api...\n","creating index...\n","index created!\n","Accumulating evaluation results...\n","DONE (t=0.39s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","2024-03-29 14:50:02,604 train.py[line:446] INFO: Created checkpoint directory\n","2024-03-29 14:50:03,499 train.py[line:454] INFO: Checkpoint 2 saved !\n","Epoch 2/6:  99%|▉| 200/202 [00:40<00:00,  4.92img/\n","Epoch 3/6:  99%|▉| 200/202 [00:24<00:00, 10.37img/in function convert_to_coco_api...\n","creating index...\n","index created!\n","Accumulating evaluation results...\n","Epoch 3/6:  99%|▉| 200/202 [00:38<00:00, 10.37img/DONE (t=0.59s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.280\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.519\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","2024-03-29 14:50:42,192 train.py[line:446] INFO: Created checkpoint directory\n","2024-03-29 14:50:43,084 train.py[line:454] INFO: Checkpoint 3 saved !\n","Epoch 3/6:  99%|▉| 200/202 [00:39<00:00,  5.05img/\n","Epoch 4/6:  99%|▉| 200/202 [00:25<00:00,  9.83img/in function convert_to_coco_api...\n","creating index...\n","index created!\n","Accumulating evaluation results...\n","DONE (t=0.46s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.398\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.636\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","2024-03-29 14:51:22,734 train.py[line:446] INFO: Created checkpoint directory\n","2024-03-29 14:51:23,632 train.py[line:454] INFO: Checkpoint 4 saved !\n","Epoch 4/6:  99%|▉| 200/202 [00:40<00:00,  4.93img/\n","Epoch 5/6:  99%|▉| 200/202 [00:25<00:00,  9.63img/in function convert_to_coco_api...\n","creating index...\n","index created!\n","Accumulating evaluation results...\n","DONE (t=0.45s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.813\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.462\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.422\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.694\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","2024-03-29 14:52:02,578 train.py[line:446] INFO: Created checkpoint directory\n","2024-03-29 14:52:03,463 train.py[line:454] INFO: Checkpoint 5 saved !\n","Epoch 5/6:  99%|▉| 200/202 [00:39<00:00,  5.02img/\n","Epoch 6/6:  99%|▉| 200/202 [00:25<00:00, 10.06img/in function convert_to_coco_api...\n","creating index...\n","index created!\n","Accumulating evaluation results...\n","DONE (t=0.70s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.910\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.444\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.524\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.416\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.636\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.706\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","2024-03-29 14:52:42,197 train.py[line:446] INFO: Created checkpoint directory\n","Epoch 6/6:  99%|▉| 200/202 [00:38<00:00, 10.06img/2024-03-29 14:52:43,073 train.py[line:454] INFO: Checkpoint 6 saved !\n","Epoch 6/6:  99%|▉| 200/202 [00:39<00:00,  5.05img/\n"]}],"source":["# !python train.py -l 0.001 -g 0 -pretrained checkpoints/Yolov4_epoch294.pth -classes 12 -dir train"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4055,"status":"ok","timestamp":1711725269735,"user":{"displayName":"Gia Huy Tong","userId":"14695060995051312742"},"user_tz":-420},"id":"DwM9h13DtpHP","outputId":"f7df8c0a-a673-43c3-f95f-fcf1f2bb5f6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------------------\n","           Preprocess : 0.001686\n","      Model Inference : 0.277218\n","-----------------------------------\n","-----------------------------------\n","       max and argmax : 0.001661\n","                  nms : 0.000524\n","Post processing total : 0.002185\n","-----------------------------------\n","-----------------------------------\n","           Preprocess : 0.002725\n","      Model Inference : 0.043769\n","-----------------------------------\n","-----------------------------------\n","       max and argmax : 0.001140\n","                  nms : 0.000476\n","Post processing total : 0.001616\n","-----------------------------------\n","black-bishop: 0.592739\n","black-bishop: 0.451561\n","black-king: 0.906785\n","black-pawn: 0.829600\n","black-pawn: 0.803572\n","white-bishop: 0.823456\n","white-king: 0.923237\n","white-pawn: 0.709624\n","save plot results to predictions.jpg\n"]}],"source":["img=\"cfc306bf86176b92ffc1afbb98d7896f_jpg.rf.2de0d2da0025b5993598f47fb1d51d10.jpg\"\n","!python models.py 12 checkpoints/Yolov4_epoch6.pth test/$img 416 416 test/_classes.txt"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
